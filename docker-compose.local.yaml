services:
  dokeep-application:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8081:8081"
    environment:
      - DISABLE_AI=${DISABLE_AI:-0}
      - DOKEEP_ENV=docker
    volumes:
      - ./data:/app/data
      - ./uploads:/app/uploads
    depends_on:
      - dokeep-service
    restart: unless-stopped

  dokeep-service:
    build:
      context: ./py-service
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./uploads:/app/uploads
    restart: unless-stopped

  llm-service:
    build:
      context: ./llm-service
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    environment:
      - OLLAMA_HOST=${OLLAMA_HOST:-http://host.docker.internal:11434}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-qwen2:0.5b}
    volumes:
      - ollama_models:/root/.ollama

volumes:
  data:
  uploads:
  ollama_models: 